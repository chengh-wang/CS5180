{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31b1f1b8",
   "metadata": {},
   "source": [
    "# Please install the following python libraries\n",
    "- python3: https://www.python.org/\n",
    "- numpy: https://numpy.org/install/\n",
    "- tqdm: https://github.com/tqdm/tqdm#installation\n",
    "- matplotlib: https://matplotlib.org/stable/users/installing/index.html\n",
    "- scipy: https://scipy.org/install/\n",
    "- gym: https://github.com/openai/gym \n",
    "\n",
    "If you encounter the error: \"IProgress not found. Please update jupyter & ipywidgets\"\n",
    "    \n",
    "Please install the ipywidgets as follows:\n",
    "\n",
    "    with pip, do\n",
    "    - pip install ipywidgets\n",
    "    \n",
    "    with conda, do\n",
    "    - conda install -c conda-forge ipywidgets\n",
    "    \n",
    "Restart your notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c4ab46",
   "metadata": {},
   "source": [
    "# Implementation of the Windy GridWorld environment in Example 6.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d007d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "904aca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Windy GridWorld Env\"\"\"\n",
    "class WindyGridWorld(object):\n",
    "    def __init__(self, enable_king_move=False, enable_no_move=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            enable_king_move (bool): If True, using King's movement. Otherwise, using the original action space.\n",
    "            enable_no_move (bool): If True, adding no movement under the condition of enable_king_move = True.\n",
    "        \n",
    "        Note: for different setup, we have the following action spaces:\n",
    "            - Original: [\"up\", \"down\", \"left\", \"right\"];\n",
    "            - King's move: [\"up\", \"down\", \"left\", \"right\", \"up-left\", \"up-right\", \"down-left\", \"down-right\"];\n",
    "            - King's move + no move: [\"up\", \"down\", \"left\", \"right\", \"up-left\", \"up-right\", \"down-left\", \"down-right\", \"stay\"]\n",
    "        \"\"\"\n",
    "        \n",
    "        # define the grid space\n",
    "        self.grid = np.zeros((7, 10))\n",
    "\n",
    "        # define the state space\n",
    "        self.state_space = [[r, c] for r, c in zip(np.where(self.grid == 0.0)[0],\n",
    "                                                   np.where(self.grid == 0.0)[1])]\n",
    "\n",
    "        # define the start state\n",
    "        self.start_state = [3, 0]\n",
    "\n",
    "        # define the goal state\n",
    "        self.goal_state = [3, 7]\n",
    "\n",
    "        # define the wind\n",
    "        self.wind = np.array([0, 0, 0, 1, 1, 1, 2, 2, 1, 0], dtype=int)\n",
    "\n",
    "        # define the action space\n",
    "        if enable_king_move:\n",
    "            # add King's move actions\n",
    "            if enable_no_move:\n",
    "                self.action_space = {\n",
    "                    \"up\": np.array([-1, 0]),\n",
    "                    \"down\": np.array([1, 0]),\n",
    "                    \"left\": np.array([0, -1]),\n",
    "                    \"right\": np.array([0, 1]),\n",
    "                    \"up-right\": np.array([-1, 1]),  # add up-right\n",
    "                    \"up-left\": np.array([-1, -1]),  # add up-left\n",
    "                    \"down-right\": np.array([1, 1]),  # add down-right\n",
    "                    \"down-left\": np.array([1, -1]),  # add down-left\n",
    "                    \"stay\": np.array([0, 0])  # add no move action\n",
    "                }\n",
    "            else:\n",
    "                # add King's move actions + one no movement action\n",
    "                self.action_space = {\n",
    "                    \"up\": np.array([-1, 0]),\n",
    "                    \"down\": np.array([1, 0]),\n",
    "                    \"left\": np.array([0, -1]),\n",
    "                    \"right\": np.array([0, 1]),\n",
    "                    \"up-right\": np.array([-1, 1]),  # add up-right\n",
    "                    \"up-left\": np.array([-1, -1]),  # add up-left\n",
    "                    \"down-right\": np.array([1, 1]),  # add down-right\n",
    "                    \"down-left\": np.array([1, -1])  # add down-left\n",
    "                }\n",
    "        else:\n",
    "            # normal actions\n",
    "            self.action_space = {\n",
    "                \"up\": np.array([-1, 0]),\n",
    "                \"down\": np.array([1, 0]),\n",
    "                \"left\": np.array([0, -1]),\n",
    "                \"right\": np.array([0, 1])\n",
    "            }\n",
    "\n",
    "        # track the current state, time step, and action\n",
    "        self.state = None\n",
    "        self.t = None\n",
    "        self.act = None\n",
    "\n",
    "    def reset(self):\n",
    "        # reset the agent to the start state\n",
    "        self.state = self.start_state\n",
    "        # reset the time step tracker\n",
    "        self.t = 0\n",
    "        # reset the action tracker\n",
    "        self.act = None\n",
    "        # reset the terminal flag\n",
    "        terminated = False\n",
    "        return self.state, terminated\n",
    "\n",
    "    def step(self, act):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            act (string): a string variable indicating the action.\n",
    "        \"\"\"\n",
    "        # obtain the state array\n",
    "        s_arr = np.array(self.state)\n",
    "\n",
    "        # obtain the action array\n",
    "        act_arr = self.action_space[act.lower()]\n",
    "\n",
    "        # obtain the wind array\n",
    "        wind_arr = -1 * np.array([self.wind[self.state[1]], 0], dtype=int)\n",
    "\n",
    "        # compute the next state\n",
    "        next_s_arr = np.clip(s_arr + act_arr + wind_arr,\n",
    "                             a_min=np.array([0, 0]),\n",
    "                             a_max=np.array([self.grid.shape[0]-1, self.grid.shape[1]-1]))\n",
    "\n",
    "        # compute the reward\n",
    "        reward = 0 if next_s_arr.tolist() == self.goal_state else -1\n",
    "\n",
    "        # check the termination\n",
    "        terminated = True if reward == 0 else False\n",
    "\n",
    "        # update the tracking variables\n",
    "        self.state = next_s_arr.tolist()\n",
    "        self.t += 1\n",
    "        self.act = act\n",
    "\n",
    "        return self.state, reward, terminated\n",
    "\n",
    "    def render(self):\n",
    "        # plot the agent and the goal\n",
    "        # agent = 1\n",
    "        # goal = 2\n",
    "        plot_arr = self.grid.copy()\n",
    "        plot_arr[self.state[0], self.state[1]] = 1.0\n",
    "        plot_arr[self.goal_state[0], self.goal_state[1]] = 2.0\n",
    "        plt.clf()\n",
    "        fig, arr = plt.subplots(1, 1)\n",
    "        arr.set_title(f\"state={self.state}, act={self.act}\")\n",
    "        arr.imshow(plot_arr)\n",
    "        plt.show(block=False)\n",
    "        plt.pause(1)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "741780fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plot function similar to Ex1\"\"\"\n",
    "def plot_curves(arr_list, legend_list, color_list, ylabel, fig_title):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        arr_list (list): list of results arrays to plot\n",
    "        legend_list (list): list of legends corresponding to each result array\n",
    "        color_list (list): list of color corresponding to each result array\n",
    "        ylabel (string): label of the Y axis\n",
    "\n",
    "        Note that, make sure the elements in the arr_list, legend_list and color_list are associated with each other correctly.\n",
    "        Do not forget to change the ylabel for different plots.\n",
    "    \"\"\"\n",
    "    # set the figure type\n",
    "    plt.clf()\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # PLEASE NOTE: Change the labels for different plots\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlabel(\"Time Steps\")\n",
    "\n",
    "    # ploth results\n",
    "    h_list = []\n",
    "    for arr, legend, color in zip(arr_list, legend_list, color_list):\n",
    "        # compute the standard error\n",
    "        arr_err = arr.std(axis=0) / np.sqrt(arr.shape[0])\n",
    "        # plot the mean\n",
    "        h, = ax.plot(range(arr.shape[1]), arr.mean(axis=0), color=color, label=legend)\n",
    "        # plot the confidence band\n",
    "        arr_err = 1.96 * arr_err\n",
    "        ax.fill_between(range(arr.shape[1]), arr.mean(axis=0) - arr_err, arr.mean(axis=0) + arr_err, alpha=0.3,\n",
    "                        color=color)\n",
    "        # save the plot handle\n",
    "        h_list.append(h)\n",
    "\n",
    "    # plot legends\n",
    "    ax.set_title(f\"{fig_title}\")\n",
    "    ax.legend(handles=h_list)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c983fa",
   "metadata": {},
   "source": [
    "# Test Windy GridWorld "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3324ad53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 0: state = [3, 0], action = right,  reward = -1, next_state = [2, 0], done = False\n",
      "t = 1: state = [3, 0], action = up,  reward = -1, next_state = [1, 0], done = False\n",
      "t = 2: state = [3, 0], action = left,  reward = -1, next_state = [0, 0], done = False\n",
      "t = 3: state = [3, 0], action = down,  reward = -1, next_state = [0, 0], done = False\n",
      "t = 4: state = [3, 0], action = down,  reward = -1, next_state = [0, 0], done = False\n",
      "t = 5: state = [3, 0], action = right,  reward = -1, next_state = [0, 0], done = False\n",
      "t = 6: state = [3, 0], action = down,  reward = -1, next_state = [0, 0], done = False\n",
      "t = 7: state = [3, 0], action = left,  reward = -1, next_state = [0, 0], done = False\n",
      "t = 8: state = [3, 0], action = right,  reward = -1, next_state = [0, 0], done = False\n",
      "t = 9: state = [3, 0], action = left,  reward = -1, next_state = [0, 0], done = False\n"
     ]
    }
   ],
   "source": [
    "# check whether enable King's movement and no movement\n",
    "use_king_move = False\n",
    "use_no_move = False\n",
    "\n",
    "# create the environment\n",
    "env = WindyGridWorld(enable_king_move=use_king_move,\n",
    "                     enable_no_move=use_no_move)\n",
    "s, d = env.reset()\n",
    "\n",
    "# iteracting with the environment for 10 time steps using a random policy\n",
    "for t in range(10): \n",
    "    # sample an random action\n",
    "    a = np.random.choice(list(env.action_space.keys()), 1)[0]\n",
    "    \n",
    "    # interact with the envrionment\n",
    "    next_s, r, d = env.step(action)\n",
    "    \n",
    "    # print info\n",
    "    print(f\"t = {t}: state = {s}, action = {a},  reward = {r}, next_state = {next_s}, done = {d}\")\n",
    "    \n",
    "    # check termination\n",
    "    if d:\n",
    "        s, d = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be09fa47",
   "metadata": {},
   "source": [
    "# Q4 - (a): Solve the Windy Gridworld using the following algorithms and reproduce the figure similar to the figure in Example 6.5\n",
    "\n",
    "- Implement the SARSA, Expected SARSA, and Q learning.\n",
    "- Reproduce the plot in the Example 6.5 and plot the three curves in a single plot. You can use the provided plotting code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf5acd3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' CODE HERE YOUR IMPLEMENTATION for SARSA '"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" CODE HERE YOUR IMPLEMENTATION for SARSA \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9e490dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' CODE HERE YOUR IMPLEMENTATION for Expected SARSA '"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" CODE HERE YOUR IMPLEMENTATION for Expected SARSA \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffe01f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' CODE HERE YOUR IMPLEMENTATION for Q learning '"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" CODE HERE YOUR IMPLEMENTATION for Q learning \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "027aa18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' CODE HERE YOUR IMPLEMENTATION OF FIGURE PLOTTING '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" CODE HERE YOUR IMPLEMENTATION OF FIGURE PLOTTING \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8d2bec",
   "metadata": {},
   "source": [
    "# Q4 - (b): Re-solve the Windy GridWorld with Kings' movement and No movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2b982cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Reproduce the Figure above in Windy GridWorld with King's movement \""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Reproduce the Figure above in Windy GridWorld with King's movement \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a66539fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Reproduce the Figure above in Windy GridWorld with King's movement + no movement \""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Reproduce the Figure above in Windy GridWorld with King's movement + no movement \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629ac36f",
   "metadata": {},
   "source": [
    "# Q5: Bias-variance trade-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e6889433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Please code your implementation of running the experiments here '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Please code your implementation of running the experiments here \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "876996ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Please code your implementation of plotting the histogram figure here '"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Please code your implementation of plotting the histogram figure here \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
